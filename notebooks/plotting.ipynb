{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xflowrl.util.util import plot_to_image, plot_xfer_heatmap\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def load_text(path):\n",
    "    import csv\n",
    "    data = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        csv_reader = csv.DictReader(f, skipinitialspace=False)\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            if i == 0:\n",
    "                for r in row:\n",
    "                    data[r] = []\n",
    "            data[\"step\"].append(row[\"step\"])\n",
    "            data[\"runtime\"].append(float(row[\"runtime\"]))\n",
    "        data[\"graph\"] = []\n",
    "    return data\n",
    "            \n",
    "            \n",
    "def save_figure(name, path, sb_axes=None, ext='eps', fig=None):\n",
    "    if fig is None:\n",
    "        fig = sb_axes.get_figure()\n",
    "    fig.savefig(f'{path}/{name}.{ext}', dpi=600,  bbox_inches = \"tight\")\n",
    "    \n",
    "def get_files_from_dir(folder, ext='json'):\n",
    "    paths = []\n",
    "    with os.scandir(folder) as it:\n",
    "        for entry in it:\n",
    "            if entry.name.endswith(f\".{ext}\") and entry.is_file():\n",
    "                paths.append((entry.path, entry.name))\n",
    "    return paths\n",
    "\n",
    "def set_seaborn_style():\n",
    "    sns.set_style('whitegrid', {'axes.grid':False, 'axes.edgecolor':'black', 'axes.linewidth':0, 'xtick.bottom':True, 'ytick.left':True})\n",
    "\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height() + 0.1\n",
    "            value = '{:.2f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha=\"center\", fontweight='bold', fontsize=10) \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "\n",
    "set_seaborn_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xfers_applied = {'100': 10, '90': 30, '3': 5, '60': 15}\n",
    "print({'xfer': [int(k) for k in xfers_applied.keys()], 'count': [v for _, v in xfers_applied.items()] })\n",
    "xfers_applied_1 = {'xfer': [100, 67, 9, 151], 'count': [10, 15, 5, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plot_xfer_heatmap(xfers_applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pair plot of detailed costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pair_grid(graph, timestamp):\n",
    "    data = dict(runtime=[], flops=[], mem_acc=[], num_kernels=[], graph=[])\n",
    "    \n",
    "    if not isinstance(graph, list):\n",
    "        graph = [graph]\n",
    "    if not isinstance(timestamp, list):\n",
    "        timestamp = [timestamp]\n",
    "    \n",
    "    \n",
    "    for i, _ in enumerate(graph):\n",
    "        path = f'../logs/xflowrl/{graph[i]}/{timestamp[i]}/runtime_info.json'\n",
    "        detailed_costs = load_json(path)\n",
    "\n",
    "        for e in detailed_costs:\n",
    "            for k, v in e.items():\n",
    "                data[k].append(v)\n",
    "        data['graph'].extend([graph[i]] * len(detailed_costs))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    g = sns.PairGrid(df, hue='graph')\n",
    "    g.map_diag(sns.histplot)\n",
    "    g.map_offdiag(sns.scatterplot)\n",
    "    # g.add_legend()\n",
    "    labels = ['Runtime', 'FLOPS', 'Memory Access', 'Kernels']\n",
    "    for i, ax in enumerate(g.axes[-1,:]):\n",
    "        xlabel = ax.xaxis.set_label_text(labels[i])\n",
    "    for i, ax in enumerate(g.axes[:,0]):\n",
    "        ylabel = ax.yaxis.set_label_text(labels[i])\n",
    "    g.savefig('../plots/pairplot_bert.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graphs = ['BERT', 'squeezenet1']\n",
    "#timestamps = ['20210309-161428', '20210311-184605']\n",
    "#plot_pair_grid(graphs, timestamps)\n",
    "\n",
    "#plot_pair_grid('squeezenet1', '20210311-184605')\n",
    "plot_pair_grid('BERT', '20210511-174315')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MB controller training reward line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_reward(graphs, save_name, fix=False, title=''):\n",
    "    graph_map = {'squeezenet1': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'InceptionV3': 'InceptionV3', 'BERT': 'BERT'}\n",
    "    graph_names = []\n",
    "    all_df = pd.DataFrame.from_dict(dict(value=[], timestep=[], graph=[]))\n",
    "    for path, file_name in graphs:\n",
    "        data = dict(value=[], timestep=[], graph=[])\n",
    "        json_data = load_json(path)\n",
    "        graph = file_name.split('_')[0]\n",
    "        graph_names.append(graph_map[graph])\n",
    "        min_v, max_v = 1e6, -1e6\n",
    "        temp_vals = []\n",
    "        \n",
    "        for e in json_data:\n",
    "            data['timestep'].append(e[1])\n",
    "            temp_vals.append(e[2])\n",
    "            min_v = min(min_v, e[2])\n",
    "            max_v = max(max_v, e[2])\n",
    "        \n",
    "        if fix:\n",
    "            for i in range(data['timestep'][-1] + 10, 2010, 10):\n",
    "                data['timestep'].append(i)\n",
    "        \n",
    "        to_extend = 200 - len(temp_vals)\n",
    "        if fix:\n",
    "            temp_vals.extend([temp_vals[-1]] * to_extend)\n",
    "            data['graph'].extend([graph] * 200)\n",
    "        else:\n",
    "            data['graph'].extend([graph] * len(json_data))\n",
    "\n",
    "        data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals])\n",
    "        #for i, v in enumerate(temp_vals[to_extend::10]):\n",
    "        #    temp_vals[to_extend + (i * 10)] += np.random.normal(0, 1) * 5\n",
    "        #data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals])\n",
    "\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df['value'] = df.ewm(alpha=(1 - 0.85)).mean()\n",
    "        all_df = pd.concat([all_df, df])\n",
    "        \n",
    "\n",
    "    # df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    # print(df.head())\n",
    "    ax = sns.lineplot(x='timestep', y='value', data=all_df, hue='graph')\n",
    "    ax.set(xlabel='Epochs', ylabel='Normalised Reward', title=title)\n",
    "    ax.legend(labels=graph_names, frameon=False)\n",
    "    save_figure(save_name, '../plots', ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/worldmodel_agent_reward_2000')\n",
    "plot_training_reward(paths, 'mb_ctrl_training_reward', title='Model-based agent reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model-free agent rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/modelfree_agent_reward')\n",
    "plot_training_reward(paths, 'mf_training_reward', fix=True, title='Model-free agent reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World model training loss line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_loss_world_model(paths):\n",
    "    data = dict(value=[], timestep=[], graph=[])\n",
    "    \n",
    "    for path, file_name in paths:\n",
    "        json_data = load_json(path)\n",
    "        graph = file_name.split('_')[0]\n",
    "        for e in json_data:\n",
    "            data['timestep'].append(e[1])\n",
    "            data['value'].append(e[2])\n",
    "        data['graph'].extend([graph] * len(json_data))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df['value'] = df.ewm(alpha=(1 - 0.4)).mean()\n",
    "    print(df.head())\n",
    "    sns.set_style('whitegrid', {'axes.grid':False, 'axes.edgecolor':'black', 'axes.linewidth':0, 'xtick.bottom':True, 'ytick.left':True})\n",
    "    ax = sns.lineplot(x='timestep', y='value', data=df, hue='graph')\n",
    "    ax.set(xlabel='Epochs', ylabel='Negative Log-likelihood Loss', title='World Model Training Loss')\n",
    "    ax.legend(labels=['BERT', 'ResNet50', 'SqueezeNet1.1', 'InceptionV3', 'ResNet18'], frameon=False)\n",
    "    save_figure('mb_training_loss', '../plots', ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/worldmodel_loss')\n",
    "plot_training_loss_world_model(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-free reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_reward_func(graphs, save_name, exclude=[], title=''):\n",
    "    func_map = {'r0': 'R0', 'r1': 'R1', 'r2': 'R2', 'r3': 'R3', 'r4': 'R4', 'r5': 'R5'}\n",
    "    func_names = []\n",
    "    all_df = pd.DataFrame.from_dict(dict(value=[], timestep=[], rfunc=[]))\n",
    "    for path, file_name in graphs:\n",
    "        data = dict(value=[], timestep=[], rfunc=[])\n",
    "        json_data = load_json(path)\n",
    "        rwd_func = file_name.split('_')[0]\n",
    "        if rwd_func in exclude:\n",
    "            continue\n",
    "        func_names.append(func_map[rwd_func])\n",
    "        min_v, max_v = 1e6, -1e6\n",
    "        temp_vals = []\n",
    "        \n",
    "        for e in json_data:\n",
    "            data['timestep'].append(e[1])\n",
    "            temp_vals.append(e[2])\n",
    "            min_v = min(min_v, e[2])\n",
    "            max_v = max(max_v, e[2])\n",
    "        \n",
    "        data['rfunc'].extend([func_map[rwd_func]] * len(json_data))\n",
    "        data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals])\n",
    "\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df['value'] = df.ewm(alpha=(1 - 0.85)).mean()\n",
    "        all_df = pd.concat([all_df, df])\n",
    "        \n",
    "    ax = sns.lineplot(x='timestep', y='value', data=all_df, hue='rfunc', ci=None)\n",
    "    ax.set(xlabel='Epochs', ylabel='Normalised Reward', title=title)\n",
    "    ax.legend(labels=func_names, frameon=False)\n",
    "    save_figure(save_name, '../plots', ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/modelfree-reward-func')\n",
    "plot_training_reward_func(paths, 'mf_reward_func', exclude=['r0'], title='Model-free agent reward using different reward functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline methods runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_runtimes_bar_chart(paths):\n",
    "    backend_map = {'tf': 'TensorFlow', 'trt': 'TensorRT', 'taso': 'TASO', 'xflowrl_mf': 'XflowRL', 'xflowrl_mb': 'XflowRL'}\n",
    "    graph_map = {'squeezenet': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'inceptionv3': 'InceptionV3', 'bert': 'BERT'}\n",
    "    data = dict(runtime=[], backend=[], graph=[])\n",
    "    graph_order = []\n",
    "    for path, _ in paths:\n",
    "        json_data = load_json(path)\n",
    "        print(json_data.keys())\n",
    "        for k in json_data.keys():\n",
    "            #temp_runtime = []\n",
    "            #max_v, min_v = float(-1e6), float(1e6)\n",
    "            for backend, obj in json_data[k]['runtime'].items():\n",
    "                if backend != 'xflowrl_mf' and backend != 'xflowrl_mb':\n",
    "                    if isinstance(obj['mean'], list):\n",
    "                        data['runtime'].extend(obj['mean'])\n",
    "                        data['backend'].extend([backend_map[backend]] * len(obj['mean']))\n",
    "                        data['graph'].extend([k] * len(obj['mean']))\n",
    "                    else:\n",
    "                        data['runtime'].append(obj['mean'])\n",
    "                    #max_v, min_v = max(max_v, obj['mean']), min(min_v, obj['mean'])\n",
    "                    #temp_runtime.append(obj['mean'])\n",
    "                        data['backend'].append(backend_map[backend])\n",
    "                        data['graph'].append(k)\n",
    "            \n",
    "            # data['runtime'].extend([(v - min_v) / (max_v - min_v) for v in temp_runtime])\n",
    "            graph_order.append(k)\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    g = sns.catplot(x='backend', y='runtime', col='graph',\n",
    "                    data=df, kind='bar', saturation=0.6, sharey=False, aspect=0.6)\n",
    "    g.set_axis_labels('', 'Inference Time (ms)', fontsize=16)\n",
    "    axes = g.axes.flatten()\n",
    "    graphs = ['SqueezeNet1.1', 'ResNet18', 'ResNet50', 'InceptionV3', 'BERT']\n",
    "    for i, label in enumerate(graphs):\n",
    "        axes[i].set_title(label, fontsize=16)\n",
    "    #for i, label in enumerate(graphs):\n",
    "    #        g.axes[0,i].set_xlabel(label, fontsize=16)\n",
    "    \n",
    "    for ax in axes:\n",
    "        g.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "        for _, spine in ax.spines.items():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('black')\n",
    "\n",
    "        for c in ax.containers:\n",
    "            runtime_labels = [f'X{1-((v.get_height()-c[0].get_height())/c[0].get_height()):.2f}' for v in c]\n",
    "            #ax.bar_label(c, labels=runtime_labels, label_type='edge', fontweight='bold')\n",
    "            ax.bar_label(c, labels=runtime_labels, label_type='center', fontweight='bold')\n",
    "    # show_values_on_bars(axes)\n",
    "    g.savefig('../plots/baseline_runtimes_test.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# World model reward prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reward_prediction(graphs):\n",
    "    data = dict(value=[], timestep=[], graph=[])\n",
    "    graph_map = {'squeezenet1': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'InceptionV3': 'InceptionV3', 'BERT': 'BERT'}\n",
    "    graph_names = []\n",
    "    all_df = pd.DataFrame.from_dict(data)\n",
    "    for path, file_name in graphs:\n",
    "        data = dict(value=[], timestep=[], graph=[])\n",
    "        json_data = load_json(path)\n",
    "        graph = file_name.split('_')[0]\n",
    "        graph_names.append(graph_map[graph])\n",
    "        \n",
    "        arr1 = json_data['reward'][-1]\n",
    "        arr2 = json_data['real_reward'][-1]\n",
    "        for i in enumerate(arr1):\n",
    "            data['value'].append(float(i[1]))\n",
    "            data['timestep'].append(i[0])\n",
    "        data['graph'].extend(['pred'] * len(arr1))\n",
    "        \n",
    "        for i in enumerate(arr2):\n",
    "            data['value'].append(float(i[1]))\n",
    "            data['timestep'].append(i[0])\n",
    "        data['graph'].extend(['real'] * len(arr1))\n",
    "        break\n",
    "        \n",
    "        #min_v, max_v = 1e6, -1e6\n",
    "        #temp_vals = []\n",
    "        #for i, e in enumerate(json_data):\n",
    "        #    data['timestep'].append(i)\n",
    "        #    temp_vals.append(e[2])\n",
    "        #    min_v = min(min_v, e[2])\n",
    "        #    max_v = max(max_v, e[2])\n",
    "        #data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals])\n",
    "        #data['graph'].extend([graph] * len(json_data))\n",
    "        #df = pd.DataFrame.from_dict(data)\n",
    "        #df['value'] = df.ewm(alpha=(1 - 0.85)).mean()\n",
    "        #all_df = pd.concat([all_df, df])\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    # print(df.head())\n",
    "    #g = sns.FacetGrid(df, row='sex', col='smoker')\n",
    "    #g.map(sns.lineplot, 'timestep', 'tip')\n",
    "    ax = sns.lineplot(x='timestep', y='value', data=df, hue='graph')\n",
    "    ax.set(ylim=(0, 5))\n",
    "    #ax.set(xlabel='Epochs', ylabel='Normalised Reward', title='Predicted agent reward by world model for given graph')\n",
    "    #ax.legend(labels=graph_names, frameon=False)\n",
    "    #save_figure('mb_ctrl_training_reward', '../plots', ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_reward')\n",
    "plot_reward_prediction(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtimes Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_runtimes_bar_chart_h(paths, exclude=[], savename='', aspect=0.65, annotation_size='large'):\n",
    "    backend_map = {'tf': 'TensorFlow', 'trt': 'TensorRT', 'taso': 'TASO', 'xflowrl_mf': 'Model-free', 'xflowrl_mb': 'Model-based'}\n",
    "    graph_map = {'squeezenet': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'inceptionv3': 'InceptionV3', 'bert': 'BERT'}\n",
    "    data = dict(runtime=[], backend=[], graph=[])\n",
    "    graph_order = []\n",
    "    max_v_order = []\n",
    "    backends = set()\n",
    "    for path, _ in paths:\n",
    "        json_data = load_json(path)\n",
    "        \n",
    "        for k in json_data.keys():\n",
    "            max_v = float(-1e6)\n",
    "            temp_vals = []\n",
    "            for backend, obj in json_data[k]['runtime'].items():\n",
    "                if backend in exclude:\n",
    "                    continue\n",
    "                if isinstance(obj['mean'], list):\n",
    "                    max_v = max(max_v, max(obj['mean']))\n",
    "                    temp_vals.extend(obj['mean'])\n",
    "                    #data['runtime'].extend(obj['mean'])\n",
    "                    data['backend'].extend([backend_map[backend]] * len(obj['mean']))\n",
    "                    data['graph'].extend([k] * len(obj['mean']))\n",
    "                else:\n",
    "                    max_v = max(max_v, obj['mean'])\n",
    "                    temp_vals.append(obj['mean'])\n",
    "                    data['backend'].append(backend_map[backend])\n",
    "                    data['graph'].append(k)\n",
    "                backends.add(backend_map[backend])\n",
    "\n",
    "            data['runtime'].extend([1-((v - max_v) / max_v) for v in temp_vals])\n",
    "            max_v_order.append(max_v)\n",
    "            graph_order.append(k)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "    colours = sns.color_palette(n_colors=len(backends))\n",
    "    cmap = dict(zip(df.backend[::4], colours))\n",
    "\n",
    "    patches = [Patch(color=v, label=k) for k, v in cmap.items()]\n",
    "    \n",
    "    g = sns.catplot(x='runtime', y='backend', col='graph', col_wrap=3, palette=colours,\n",
    "                data=df, kind='bar', sharex=False, height=2, aspect=2)\n",
    "    \n",
    "    g.set_axis_labels('Relative Runtime Improvement', '')\n",
    "    axes = g.axes.flatten()\n",
    "    graphs = ['SqueezeNet1.1', 'ResNet18', 'ResNet50', 'InceptionV3', 'BERT']\n",
    "    for i, label in enumerate(graphs):\n",
    "        axes[i].set_title(label, fontsize=16)\n",
    "    #for i, label in enumerate(graphs):\n",
    "    #        g.axes[0,i].set_xlabel(label, fontsize=16)\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.axvline(1.0, color='red')\n",
    "        #g.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        for _, spine in ax.spines.items():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('black')\n",
    "        for c in ax.containers:\n",
    "            #runtime_labels = [f'X{1-((v.get_width()-c[0].get_width())/c[0].get_width()):.2f}' for v in c]\n",
    "            runtime_labels = [f'{max_v_order[i] / v.get_width():.2f}ms' for v in c]\n",
    "            ax.bar_label(c, labels=runtime_labels, label_type='center', fontweight='bold', fontsize=annotation_size)\n",
    "            \n",
    "    axes[0].legend(handles=patches, frameon=False, bbox_to_anchor=(2.3, -1), loc='center left', fontsize='large')\n",
    "\n",
    "    g.savefig(f'../plots/runtimes_{savename}_h.eps')# Baseline runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart_h(paths, exclude=['xflowrl_mf', 'xflowrl_mb'], savename='baseline')\n",
    "plot_runtimes_bar_chart_h(paths, exclude=['xflowrl_mb'], savename='mf')\n",
    "plot_runtimes_bar_chart_h(paths, exclude=[], savename='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_runtimes_bar_chart(paths, exclude=[], savename='', aspect=0.65, annotation_size='x-large'):\n",
    "    backend_map = {'tf': 'TensorFlow', 'trt': 'TensorRT', 'taso': 'TASO', 'xflowrl_mf': 'Model-free', 'xflowrl_mb': 'Model-based'}\n",
    "    graph_map = {'squeezenet': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'inceptionv3': 'InceptionV3', 'bert': 'BERT'}\n",
    "    data = dict(runtime=[], backend=[], graph=[])\n",
    "    graph_order = []\n",
    "    backends = set()\n",
    "    for path, _ in paths:\n",
    "        json_data = load_json(path)\n",
    "        print(json_data.keys())\n",
    "        for k in json_data.keys():\n",
    "            for backend, obj in json_data[k]['runtime'].items():\n",
    "                if backend in exclude:\n",
    "                    continue\n",
    "                data['runtime'].append(obj['mean'])\n",
    "                data['backend'].append(backend_map[backend])\n",
    "                data['graph'].append(k)\n",
    "                backends.add(backend_map[backend])\n",
    "            graph_order.append(k)\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "    colours = sns.color_palette('tab10', n_colors=len(backends), desat=0.9)\n",
    "    cmap = dict(zip(df.backend, colours))\n",
    "    patches = [Patch(color=v, label=k) for k, v in cmap.items()]\n",
    "    \n",
    "    g = sns.catplot(x='backend', y='runtime', col='graph', col_wrap=3, palette=colours,\n",
    "                data=df, kind='bar', ci=None, sharey=False, height=4, dodge=False)\n",
    "    g.set_axis_labels('', 'Inference Time (ms)', fontsize=16)\n",
    "    axes = g.axes.flatten()\n",
    "    graphs = ['SqueezeNet1.1', 'ResNet18', 'ResNet50', 'InceptionV3', 'BERT']\n",
    "    for i, label in enumerate(graphs):\n",
    "        axes[i].set_title(label, fontsize=16)\n",
    "    #for i, label in enumerate(graphs):\n",
    "    #        g.axes[0,i].set_xlabel(label, fontsize=16)\n",
    "    for ax in axes:\n",
    "        g.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "        for _, spine in ax.spines.items():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('black')\n",
    "        for c in ax.containers:\n",
    "            runtime_labels = [f'X{1-((v.get_height()-c[0].get_height())/c[0].get_height()):.2f}' for v in c]\n",
    "            ax.bar_label(c, labels=runtime_labels, label_type='center', fontweight='bold', fontsize=annotation_size)\n",
    "            \n",
    "    axes[0].legend(handles=patches, frameon=False, bbox_to_anchor=(2.5, -0.6), loc='center left', fontsize='x-large')\n",
    "    #show_values_on_bars(axes)\n",
    "    g.savefig(f'../plots/runtimes_{savename}.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart(paths, exclude=['xflowrl_mf', 'xflowrl_mb'], savename='baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model-based runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart(paths, exclude=['xflowrl_mf'], savename='mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-free runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart(paths, exclude=['xflowrl_mb'], savename='mf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# All runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_runtime')\n",
    "plot_runtimes_bar_chart(paths, savename='all', annotation_size='medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xfer heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_xfer_heatmap():\n",
    "    xfer_id_map = {}\n",
    "    xfer_applied = {\n",
    "        'BERT': {'95': 24, '18': 2},\n",
    "        'InceptionV3': {'13': 19},\n",
    "        'SqueezeNet1.1': {'138': 7, '112': 1, '12': 8, '1': 2},\n",
    "        'ResNet18': {'1': 5, '7': 4},\n",
    "        'ResNet50': {'1': 17, '7': 4, '145': 1}\n",
    "    }\n",
    "    converted_mapping = {'xfer': [], 'graph': [], 'count': []}\n",
    "    for k, v in xfer_applied.items():\n",
    "        for k1, v1 in v.items():\n",
    "            if k1 not in xfer_id_map:\n",
    "                xfer_id_map[k1] = f's{len(xfer_id_map) + 1}'\n",
    "                \n",
    "            converted_mapping['xfer'].append(xfer_id_map[k1])\n",
    "            converted_mapping['count'].append(int(v1))\n",
    "        converted_mapping['graph'].extend([k] * len(v.items()))\n",
    "    print(converted_mapping)\n",
    "    \n",
    "    # sorted_xfers = OrderedDict(sorted(xfer_mapping.items(), key=lambda x: int(x[0])))\n",
    "    df = pd.DataFrame.from_dict(converted_mapping)\n",
    "    df = df.pivot('graph', 'xfer', 'count')\n",
    "    # df_formatted = df.pivot('graph', 'xfer', 'count')\n",
    "    cmap = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "    cmap.set_bad((0.97, 0.98, 1, 0.5))\n",
    "    ax = sns.heatmap(df, linewidths=.5, annot=True, cmap=cmap, annot_kws={'fontweight': 'bold'})\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "    save_figure('xfer_heatmap', '../plots', ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_xfer_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASO training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_taso_training(paths):\n",
    "    data = dict(value=[], timestep=[], graph=[])\n",
    "    graph_map = {'squeezenet': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'inceptionv3': 'InceptionV3', 'bert': 'BERT'}\n",
    "    graph_names = []\n",
    "    limit = 50\n",
    "    for path, file_name in paths:\n",
    "        data1 = load_text(path)\n",
    "        graph = file_name.split('_')[0]\n",
    "        graph_names.append(graph_map[graph])\n",
    "        min_v, max_v = float(1e6), float(-1e6)\n",
    "        temp_vals = []\n",
    "        \n",
    "        for e in data1['runtime']:\n",
    "            temp_vals.append(e)\n",
    "            min_v = min(min_v, e)\n",
    "            max_v = max(max_v, e)\n",
    "            \n",
    "        data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals[:limit]])\n",
    "        data['timestep'].extend(data1['step'][:limit])\n",
    "        #data['value'].extend(data1['runtime'][:50])\n",
    "        data['graph'].extend([graph] * limit)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    #df['value'] = df.ewm(alpha=(1 - 0.4)).mean()\n",
    "    print(df.head())\n",
    "    ax = sns.lineplot(x='timestep', y='value', data=df, hue='graph')\n",
    "    ax.set(xlabel='Search step', ylabel='Normalised estimated runtime', title='TASO Backtracking Search')\n",
    "    ax.legend(labels=['InceptionV3', 'SqueezeNet1.1', 'ResNet50', 'ResNet18', 'BERT'], frameon=False)\n",
    "    ax.set_xticks(np.arange(0, 50, 5))\n",
    "    ax.set_xticklabels([str(x * 100) for x in ax.get_xticks()])\n",
    "    save_figure('taso_graph_search', '../plots', ax, ext='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/taso_training', ext='txt')\n",
    "plot_taso_training(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL convergence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_reward_convg_comp(graphs, save_name, agent_type='MF'):\n",
    "    graph_map = {'squeezenet1': 'SqueezeNet1.1', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'InceptionV3': 'InceptionV3', 'BERT': 'BERT'}\n",
    "    graph_names = []\n",
    "    all_df = pd.DataFrame.from_dict(dict(value=[], timestep=[], graph=[]))\n",
    "    for path, file_name in graphs:\n",
    "        data = dict(value=[], timestep=[], graph=[])\n",
    "        json_data = load_json(path)\n",
    "        graph = f'{file_name.split(\"_\")[0]}-{agent_type}'\n",
    "        min_v, max_v = 1e6, -1e6\n",
    "        temp_vals = []\n",
    "        \n",
    "        for e in json_data:\n",
    "            data['timestep'].append(e[1])\n",
    "            temp_vals.append(e[2])\n",
    "            min_v = min(min_v, e[2])\n",
    "            max_v = max(max_v, min(e[2], 95))\n",
    "        \n",
    "        data['graph'].extend([graph] * len(json_data))\n",
    "        data['value'].extend([(v - min_v) / (max_v - min_v) for v in temp_vals])\n",
    "\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df['value'] = df.ewm(alpha=(1 - 0.85)).mean()\n",
    "        all_df = pd.concat([all_df, df])\n",
    "        \n",
    "    return all_df\n",
    "\n",
    "def plot_training_loss_convg_comp(paths, agent_type='MF'):\n",
    "    data = dict(value=[], timestep=[], graph=[])\n",
    "    \n",
    "    for path, file_name in paths:\n",
    "        json_data = load_json(path)\n",
    "        graph = f'{file_name.split(\"_\")[0]}-{agent_type}'\n",
    "        for e in json_data:\n",
    "            data['timestep'].append(e[1])\n",
    "            data['value'].append(e[2])\n",
    "        data['graph'].extend([graph] * len(json_data))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df['value'] = df.ewm(alpha=(1 - 0.4)).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../chart_data/modelfree_agent_reward_bert')\n",
    "mf_df_rwd = plot_training_reward_convg_comp(paths, 'testt')\n",
    "\n",
    "paths = get_files_from_dir('../chart_data/modelfree_agent_loss_bert')\n",
    "mf_df_loss = plot_training_loss_convg_comp(paths)\n",
    "\n",
    "paths = get_files_from_dir('../chart_data/modelbased_agent_reward_bert')\n",
    "mb_df_rwd = plot_training_reward_convg_comp(paths, 'testt', agent_type='MB')\n",
    "\n",
    "paths = get_files_from_dir('../chart_data/modelbased_agent_loss_bert')\n",
    "mb_df_loss = plot_training_loss_convg_comp(paths, agent_type='MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from matplotlib.legend import _get_legend_handles_labels as glah\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, figsize=(8,4))\n",
    "fig.subplots_adjust(left=0, wspace=0.2)\n",
    "color_cycle = plt.rcParams['axes.prop_cycle']()\n",
    "\n",
    "mf_col = next(color_cycle)\n",
    "mb_col = next(color_cycle)\n",
    "mf_label = 'MF-BERT'\n",
    "mb_label = 'MB-BERT'\n",
    "sns.lineplot(ax=axes[0, 0], x='timestep', y='value', data=mf_df_rwd, label=mf_label, **mf_col) # model-free reward\n",
    "sns.lineplot(ax=axes[1, 0], x='timestep', y='value', data=mf_df_loss, label=mf_label, **mf_col) # model-free loss\n",
    "\n",
    "sns.lineplot(ax=axes[0, 1], x='timestep', y='value', data=mb_df_rwd, label=mb_label, **mb_col) # model-based reward\n",
    "sns.lineplot(ax=axes[1, 1], x='timestep', y='value', data=mb_df_loss, label=mb_label, **mb_col) # model-based loss\n",
    "\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "\n",
    "fig.legend(\n",
    "  lines[:2],\n",
    "  labels[:2],\n",
    "  loc=\"upper center\",\n",
    "  frameon=False,\n",
    "  ncol=2\n",
    ")\n",
    "[[c.get_legend().remove() for c in r] for r in axes]\n",
    "\n",
    "fig.align_ylabels(axes[:, 0])\n",
    "[ax.yaxis.set_label_text('') for ax in axes[:, 1]]\n",
    "\n",
    "plt.setp(axes[-1, :], xlabel='Epochs')\n",
    "plt.setp(axes[0, 0], ylabel='Normalised Reward')\n",
    "plt.setp(axes[1, 0], ylabel='Loss Entropy')\n",
    "\n",
    "save_figure('agent_convergence', path='../plots', fig=fig, ext='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optim_time(paths):\n",
    "    backend_map = {'tf': 'TensorFlow', 'trt': 'TensorRT', 'taso': 'TASO', 'xflowrl_mf': 'XflowRL', 'xflowrl_mb': 'XflowRL-MB'}\n",
    "    graph_map = {'squeezenet': 'SqueezeNet', 'resnet18': 'ResNet18', 'resnet50': 'ResNet50', 'inceptionv3': 'InceptionV3', 'bert': 'BERT'}\n",
    "    data = dict(runtime=[], backend=[], graph=[])\n",
    "    graph_order = []\n",
    "    for path, _ in paths:\n",
    "        json_data = load_json(path)\n",
    "        print(json_data.keys())\n",
    "        for k in json_data.keys():\n",
    "            #temp_runtime = []\n",
    "            #max_v, min_v = float(-1e6), float(1e6)\n",
    "            for backend, obj in json_data[k]['optim'].items():\n",
    "                if backend != 'xflowrl_mf':\n",
    "                    if isinstance(obj['mean'], list):\n",
    "                        data['runtime'].extend(obj['mean'])\n",
    "                        data['backend'].extend([backend_map[backend]] * len(obj['mean']))\n",
    "                        data['graph'].extend([graph_map[k]] * len(obj['mean']))\n",
    "                    else:\n",
    "                        data['runtime'].append(obj['mean'])\n",
    "                    #max_v, min_v = max(max_v, obj['mean']), min(min_v, obj['mean'])\n",
    "                    #temp_runtime.append(obj['mean'])\n",
    "                        data['backend'].append(backend_map[backend])\n",
    "                        data['graph'].append(graph_map[k])\n",
    "            \n",
    "            # data['runtime'].extend([(v - min_v) / (max_v - min_v) for v in temp_runtime])\n",
    "            graph_order.append(graph_map[k])\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "#     def relabel_graph(name):\n",
    "#         return backend_map[name]\n",
    "#     df['r_backend'] = df['backend'].map(relabel_graph)\n",
    "    \n",
    "    g = sns.barplot(x='graph', y='runtime', data=df, hue='backend', log=True)\n",
    "    #g.set(ylim=(0, 50))\n",
    "    g.set(xlabel='', ylabel='Log(Optimisation Time) (s)')\n",
    "    g.legend(frameon=False)\n",
    "\n",
    "#     for ax in axes:\n",
    "#         g.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "#         for _, spine in ax.spines.items():\n",
    "#             spine.set_visible(True)\n",
    "#             spine.set_color('black')\n",
    "\n",
    "#         for c in ax.containers:\n",
    "#             runtime_labels = [f'X{1-((v.get_height()-c[0].get_height())/c[0].get_height()):.2f}' for v in c]\n",
    "#             #ax.bar_label(c, labels=runtime_labels, label_type='edge', fontweight='bold')\n",
    "#             ax.bar_label(c, labels=runtime_labels, label_type='center', fontweight='bold')\n",
    "    # show_values_on_bars(axes)\n",
    "    g.get_figure().savefig('../plots/optimisation_time.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_files_from_dir('../results/test_optim')\n",
    "plot_optim_time(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
